{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар №3/4: Расширенный EDA + Исследование сообществ и эго-сетей\n",
    "\n",
    "Приветствую Вас снова! Этот семинар посвящен трем основным вещам:\n",
    "\n",
    "1. Как производить загрузку данных с атрибутами (более «боевые» данные)\n",
    "2. Что можно сделать помимо простейшего EDA: пытаемся извлечь больше информации\n",
    "3. Что делать, если очень хочется кластеризовать социальную сеть\n",
    "\n",
    "На самом деле все очень сильно зависит от структуры данных. Не стоит думать, что можно сделать глубокий EDA либо выполнять более сложные статистические и etc. расчеты на каждом конкретном наборе данных. Все зависит очень сильно от того, что за входящие данные у нас есть и **что они из себя ДОЛЖНЫ преставлять**. Помните! Нужно всегда знать, что выступает (по крайней мере в этом) *в качестве вершин*. Без этой информации строить сети бесполезно. На прошлом семинаре Вы могли хорошо убедиться в том, что бывает, когда не знаешь о всей структуре графа.\n",
    "\n",
    "В этой связи важно иметь не только матрицу инцидентности/смежности/список ребер, но какой-то источник данных об атрибутах – того, какие признаки могут иметь наши вершины (точки/\"кружочки\") в сети. Как мы уже говорили на прошлом семинаре, для хранения информации об атрибутах используется либо `список ребер`, либо `отдельный файл`. Редко Вы сможете увидеть атрибуты вершин в матрицах, потому что в таком случае пакеты будут дико \"грустить\" и отказываться работать (Вы его скармливаете матрицей, а он ее не видит – догадываетесь, почему? (: ). Поэтому в рамках этого семинара мы также будем играть с импортом атрибутов и приклеивания их к нашей сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале произведем загрузку данных. В рамках этого семинара мы будем иметь дело с датасетом `Social circles: Facebook`. Его можно увидеть на странице > http://snap.stanford.edu/data/ego-Facebook.html . Здесь всего 10 сетей. И они не очень большие. Но в качестве последующего проектного задания Вы будете работать с данными Twitter и Google+ (которые имеют большее количество сетей (: ). Для начала будет достаточно небольшого датасета.\n",
    "\n",
    "Снова разыграем ситуацию:\n",
    "\n",
    "    Нам сказано \"спарсить\" набор данных о пользователях \"нашей\" социальной сети для того, чтобы адресовать наш новый продукт конкретной группе людей. В то же время, перед нами стоит задача внедрить продукт в такую группую, которая сможет в дальнейшем **самостоятельно** производить распространение этого продукта. У нас мало финансов для рассылки всей сети, поэтому таргетинг наше всё!\n",
    "\n",
    "Как говорится, `*OKAY_FACE*`. ПМ сказал – что нам еще остается делать? Только копать эту группу...поэтому начнем качать данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "# Рекомендуется скачать это предварительно\n",
    "data = requests.get('http://snap.stanford.edu/data/facebook.tar.gz') # это полный архив\n",
    "open('facebook.tar.gz', 'wb').write(data.content)\n",
    "\n",
    "description = requests.get('http://snap.stanford.edu/data/readme-Ego.txt') # это информация к данным\n",
    "# К сожалению, для питона нет штатных и рабочих инструментов для вложенных архивов вроде\n",
    "# такого. Это не просто .gzip файл. Это .tar архив, сжатый алгоритмом .gzip. Поэтому тут\n",
    "# придется руками поработать\n",
    "# распакуйте архив и убедитесь, что у Вас примерно такая структура получаемой папки с данными\n",
    "\n",
    "# http://snap.stanford.edu/data/readme-Ego.txt\n",
    "description.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pth = os.getcwd(); print(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(pth+\"/facebook\") is True:\n",
    "    print(os.listdir(pth+\"/facebook/\"))\n",
    "    \n",
    "else:\n",
    "    print(\"Такой структуры данных + папки нет\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как Вы могли заметить, архив после распаковки имеет большое количество файлов. На самом деле у нас 10 сетей, но они содержат кучу дополнительных атрибутов, разложенных по файлам. Теперь представляется интересным рассмотреть структуру. Начнем это в следующее секции (после черты ниже)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Экспресс анализ\n",
    "\n",
    "Как обычно, перед процессом глубинного EDA необходимо выделить общую характеристику нашей сетевой модели ( = описание нашего графа). Поэтому начнем с того, что составим список файлов в табличной форме (+ в качестве бонуса *поиграем через `plotly`*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "# https://plot.ly/python/table/\n",
    "#import plotly\n",
    "#from plotly.offline import plot\n",
    "#import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist = os.listdir(pth+\"/facebook 2/\")\n",
    "\n",
    "# если это отдельно запустить – получаем список переменных\n",
    "#for i in range(0,len(slist)):\n",
    "#    print(slist[i].split('.'))\n",
    "\n",
    "# я хочу здесь извлечь название и тип и разнести потом по колонкам\n",
    "flist = pds.DataFrame({'Name':[i.split('.')[0] for i in slist],  # это у нас имя\n",
    "                     'Type':[i.split('.')[1] for i in slist]}) # это у нас формат\n",
    "\n",
    "# если хочется видеть в виде Plotly\n",
    "#trace = go.Table(\n",
    "#    header=dict(values=list(flist.columns),\n",
    "#                fill = dict(color='#C2D4FF'),\n",
    "#                align = ['left'] * 5),\n",
    "#    cells=dict(values=[flist.Name, flist.Type],\n",
    "#               fill = dict(color='#F5F8FF'),\n",
    "#               align = ['left'] * 5))\n",
    "\n",
    "#data = [trace] \n",
    "#plot(data, filename = 'pandas_table.html')\n",
    "flist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем какой-то один датасет :) Опять делаем небольшой велосипед с модулем `random`, чтобы получить в итоге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "\n",
    "numb = set(pds.to_numeric(flist.Name))\n",
    "working_data = rd.sample(numb, 1); print(working_data)\n",
    "\n",
    "# случайным образом оказалось число 348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окей, будем играть с массивом `348`. Еще раз взглянем тогда на структуру данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist[25:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть 5 файлов, но с разными характеристиками. Мы должны разобраться в этих данных. Как минимум, посмотреть на названия файлов. К счатью кодировщики данных заботливо для нас заготовили все файлы и вместо того, чтобы обозначать их как `.txt` оставили в качестве расширений наименования файлов. Посмотрим примерно на то, что там лежит..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(os.getcwd()+'/facebook') # мы перешли к папке с данными\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "edges = pds.read_csv('348.edges', sep = ' ', header = None, names = ['id1', 'id2'])\n",
    "nodes = pds.read_csv('348.node_attributes.csv', sep = ' ', skiprows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds.read_csv('348.edges', sep = ' ', header = None, names = ['id1', 'id2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По крайней мере, мы здесь видим список ребер (`.edges`), список атрибутов/фичей для списка ребер (`.feat`), названия атрибутов для списка фичей (`.featnames`) и эго-сеть (`ego`). А еще был файл с атрибутами вершин. Его не было в исходном датасете. Я его сгенерировал. Окей, давайте вначале проделаем штатный EDA и потом попробуем что-нибудь сложнее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for index, row in nodes.iterrows():\n",
    "    G.add_node(row[\"ID\"], name = row[\"NAME\"], gender = row[\"GENDER\"], city = row[\"CITY\"] )\n",
    "for index, row in edges.iterrows():\n",
    "    G.add_edge(row[\"id1\"], row[\"id2\"])\n",
    "    \n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pds.DataFrame({'Базовый показатель':\n",
    "                          [\n",
    "                              'Число вершин',\n",
    "                              'Число ребер',\n",
    "                              'Уровень транзитивности',\n",
    "                              'Уровень плотности',\n",
    "                              'Направленность сети',\n",
    "                              'Взвешенность сети',\n",
    "                              'Максимальная центральность',\n",
    "                              'Максимальное посредничество',\n",
    "                              'Максимальная близость',\n",
    "                              'Средняя близость',\n",
    "                              'Среднее посредничество',\n",
    "                              'Средняя центральность'\n",
    "                          ],\n",
    "                          'Значения':[\n",
    "                              round(nx.number_of_nodes(G), 2),\n",
    "                              round(nx.number_of_edges(G), 2),\n",
    "                              round(nx.transitivity(G)*100, 2),\n",
    "                              round(nx.density(G)*100, 2),\n",
    "                              nx.is_directed(G),\n",
    "                              nx.is_weighted(G),\n",
    "                              max(dict(nx.degree(G)).values()),\n",
    "                              round(max(dict(nx.betweenness_centrality(G)).values())*100,2),\n",
    "                              round(max(dict(nx.closeness_centrality(G)).values())*100,2),\n",
    "                              round(np.mean(tuple(dict(nx.closeness_centrality(G)).values())),2),\n",
    "                              round(np.mean(tuple(dict(nx.betweenness_centrality(G)).values())),2),\n",
    "                              round(np.mean(tuple(dict(nx.degree_centrality(G)).values())),2)\n",
    "                          ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "\n",
    "plt.figure(figsize=[20,10])\n",
    "xticks([]), yticks([])\n",
    "\n",
    "subplot(2,2,1)\n",
    "title('Степень Центральности (в абсолютных значениях)')\n",
    "xlabel('Номер наблюдаемой вершины')\n",
    "ylabel('Кол-во связей (общее)')\n",
    "plt.bar(dict(nx.degree(G)).keys(), dict(nx.degree(G)).values())\n",
    "#plt.plot(nx.degree(G))\n",
    "\n",
    "subplot(2,2,2)\n",
    "title('Степень Центральности (в относительных значениях)')\n",
    "xlabel('Номер наблюдаемой вершины')\n",
    "ylabel('Степень (*100%)')\n",
    "#plt.plot(nx.degree_centrality(G).values(), color = 'green')\n",
    "plt.bar(dict(nx.degree_centrality(G)).keys(), dict(nx.degree_centrality(G)).values())\n",
    "\n",
    "subplot(2,2,3)\n",
    "title('Уровень Посредничества (в относительных значениях)')\n",
    "xlabel('Номер наблюдаемой вершины')\n",
    "ylabel('Степень (*100%)')\n",
    "plt.plot(nx.betweenness_centrality(G).values(), color = 'red')\n",
    "\n",
    "subplot(2,2,4)\n",
    "title('Степень Близости (в относительных значениях)')\n",
    "xlabel('Номер наблюдаемой вершины')\n",
    "ylabel('Степень (*100%)')\n",
    "plt.plot(nx.closeness_centrality(G).values(), color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(nx.degree(G)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# я попробовал запихнуть все в одну таблицу\n",
    "frt_table = pds.DataFrame({'Индикатор':\n",
    "                          [\n",
    "                              'Число ребер',\n",
    "                              'Уровень транзитивности',\n",
    "                              'Уровень плотности',\n",
    "                              'Направленность сети',\n",
    "                              'Взвешенность сети',\n",
    "                              'Максимальная центральность',\n",
    "                              'Максимальное посредничество',\n",
    "                              'Максимальная близость',\n",
    "                              'Средняя близость',\n",
    "                              'Среднее посредничество',\n",
    "                              'Средняя центральность'\n",
    "                          ],\n",
    "                          'Номер':[\n",
    "                              round(nx.number_of_edges(G), 2),\n",
    "                              round(nx.transitivity(G)*100, 2),\n",
    "                              round(nx.density(G), 2),\n",
    "                              nx.is_directed(G),\n",
    "                              nx.is_weighted(G),\n",
    "                              max(dict(nx.degree(G)).values()),\n",
    "                              round(max(dict(nx.betweenness_centrality(G)).values())*100,2),\n",
    "                              round(max(dict(nx.closeness_centrality(G)).values())*100,2),\n",
    "                              round(np.mean(tuple(dict(nx.closeness_centrality(G)).values())),2),\n",
    "                              round(np.mean(tuple(dict(nx.betweenness_centrality(G)).values())),2),\n",
    "                              round(np.mean(tuple(dict(nx.degree_centrality(G)).values())),2)\n",
    "                          ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_table = pds.DataFrame({\n",
    "               'Имя': nx.get_node_attributes(G, 'name'),\n",
    "               'Город': nx.get_node_attributes(G, 'city'),\n",
    "               'Число связей': dict(nx.degree(G)),\n",
    "               'Ст. Центр.': nx.degree_centrality(G),\n",
    "               'Ст. Посред.': nx.betweenness_centrality(G),\n",
    "               'Ст. Близости': nx.closeness_centrality(G),\n",
    "               'Ст. Собс. Вектора': nx.eigenvector_centrality(G)\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frt_table, '\\n\\n', sec_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_table.sort_values(by = 'Ст. Центр.', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_table.sort_values(by = 'Ст. Центр.', ascending=False).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "#cc.fire\n",
    "\n",
    "plt.figure(figsize=[20,20])\n",
    "graph_1 = nx.draw(G, labels = nx.get_node_attributes(G, 'name'),\n",
    "                 font_size = 8,\n",
    "                  node_size = np.array(tuple(list(nx.betweenness_centrality(G).values())))*10000,\n",
    "                  node_color = cc.fire[0:224])\n",
    "\n",
    "plt.title(\"The Facebook contacts network\")\n",
    "plt.savefig('Graph1.PDF', format = \"PDF\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "\n",
    "nx.draw_shell(G, node_color = 'red', with_labels = True,\n",
    "             node_size = 200, font_size = 8)\n",
    "plt.title(\"The Facebook contacts network\")\n",
    "plt.savefig('Graph2.PDF', format = \"PDF\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "\n",
    "nx.draw_kamada_kawai(G, node_color = 'aqua', with_labels = True,\n",
    "             node_size = 200, font_size = 8)\n",
    "plt.title(\"The Facebook contacts network\")\n",
    "plt.savefig('Graph3.PDF', format = \"PDF\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, dict(nx.degree(G)), 'size_node')\n",
    "np.array(nx.get_node_attributes(G, 'size_node'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_node_attributes(G, 'name')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
